{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848985a8",
   "metadata": {},
   "source": [
    "# GraphRAG on Financial Knowledge Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ef5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import GraphIndexCreator\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.indexes.graph import NetworkxEntityGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c43671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ······································································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95006f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Core LC Chat Interface\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084c82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge graph data has been successfully saved.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, ast\n",
    "\n",
    "def load_mapping(file_path):\n",
    "    \"\"\"Load mapping from ID to name.\"\"\"\n",
    "    mapping = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                id_str, name = parts\n",
    "                mapping[id_str] = name\n",
    "#                 print(mapping)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "\n",
    "def load_triplets_from_files(directory_path):\n",
    "    \"\"\"Load triplets from all files in the given directory.\"\"\"\n",
    "    triplets = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = file.read()\n",
    "                data_dict = ast.literal_eval(data)  # Safely evaluate the string to a dictionary\n",
    "                triplets.extend(data_dict.get('output', []))\n",
    "    return triplets\n",
    "\n",
    "\n",
    "def write_knowledge_graph(triplets, entity_mapping, relation_mapping, output_file_path):\n",
    "    \"\"\"Write the knowledge graph data to an output file.\"\"\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        for triplet in triplets:\n",
    "            if len(triplet) == 5:\n",
    "                head, head_type, relation, tail, tail_type = triplet\n",
    "                head_name = entity_mapping.get(head, head)\n",
    "                relation_name = relation_mapping.get(relation, relation)\n",
    "                tail_name = entity_mapping.get(tail, tail)\n",
    "                file.write(f\"{head_name}\\t{relation_name}\\t{tail_name}\\n\")\n",
    "\n",
    "\n",
    "def main(entity_file, relation_file, triplets_directory, output_file):\n",
    "    entity_mapping = load_mapping(entity_file)\n",
    "    relation_mapping = load_mapping(relation_file)\n",
    "    triplets = load_triplets_from_files(triplets_directory)\n",
    "    write_knowledge_graph(triplets, entity_mapping, relation_mapping, output_file)\n",
    "    print(\"Knowledge graph data has been successfully saved.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Build a knowledge graph from triplets and mappings.\")\n",
    "#     parser.add_argument(\"entity_file\", help=\"Path to the entity mapping file.\")\n",
    "#     parser.add_argument(\"relation_file\", help=\"Path to the relation mapping file.\")\n",
    "#     parser.add_argument(\"triplets_directory\", help=\"Directory containing triplet files.\")\n",
    "#     parser.add_argument(\"output_file\", help=\"Path to the output file for the knowledge graph.\")\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "#     main(args.entity_file, args.relation_file, args.triplets_directory, args.output_file)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Build knowledge graph from entity, relation, and triplet files.\")\n",
    "#     parser.add_argument(\"entity_file\", type=str, help=\"Path to the entity file.\")\n",
    "#     parser.add_argument(\"relation_file\", type=str, help=\"Path to the relation file.\")\n",
    "#     parser.add_argument(\"triplets_directory\", type=str, help=\"Directory containing triplet files.\")\n",
    "#     parser.add_argument(\"output_file\", type=str, help=\"Path to the output file where the knowledge graph will be saved.\")\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "main(\"test_entity2id.txt\", \"test_relation2id.txt\", \"../../data/news_articles/processed/us-financial-news-articles/output/test_set/\", \"test_kg.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_creator = GraphIndexCreator(llm=ChatNVIDIA(model=\"mixtral_8x7b\", temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3044b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_graph = NetworkxEntityGraph.from_gml(\"test_graph.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f80e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entities(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    all_entities = {}\n",
    "    for line in lines:\n",
    "        entity, id = line.strip().split(\"\\t\")\n",
    "        all_entities[int(id)] = entity\n",
    "    \n",
    "    return all_entities\n",
    "\n",
    "def load_relations(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    all_relations = {}\n",
    "    for line in lines:\n",
    "        relation, id = line.strip().split(\"\\t\")\n",
    "        all_relations[int(id)] = relation\n",
    "    \n",
    "    return all_relations\n",
    "\n",
    "def get_relation_tuples(all_entities, all_relations, dataset):\n",
    "    # load the data\n",
    "    lines = open(dataset).readlines()\n",
    "    all_tuples = []\n",
    "    for line in lines:\n",
    "        subject, relation, obj= line.strip().split(\"\\t\")\n",
    "        all_tuples.append((all_entities[int(subject)], all_relations[int(relation)], all_entities[int(obj)]))\n",
    "    return all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0e9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_ID_MAP = \"test_entity2id.txt\"\n",
    "RELATION_ID_MAP = \"test_relation2id.txt\"\n",
    "# test/train data: The first four columns correspond to subject (entity), relation, object (entity), and time.\n",
    "DATASET = \"test_kg.txt\"\n",
    "\n",
    "all_entities = load_entities(ENTITY_ID_MAP)\n",
    "all_relations = load_relations(RELATION_ID_MAP)\n",
    "knowledge_graph = get_relation_tuples(all_entities, all_relations, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d126814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes.graph import NetworkxEntityGraph\n",
    "from langchain.graphs.networkx_graph import KnowledgeTriple\n",
    "\n",
    "graph = NetworkxEntityGraph()\n",
    "for item in knowledge_graph:\n",
    "    kt = KnowledgeTriple(item[0], item[1], item[2])\n",
    "    graph.add_triple(kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699b16ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('California', 'Minimum Wage', 'Raise'),\n",
       " ('California', 'More than 2 million workers', 'Impact'),\n",
       " ('Maine', 'Minimum Wage', 'Raise'),\n",
       " ('Maine', 'An estimated 59,000 workers', 'Impact'),\n",
       " ('National Employment Law Project',\n",
       "  '18 states and 19 cities will boost minimum wage',\n",
       "  'Announce'),\n",
       " ('Economic Policy Institute', 'Figures', 'Compile'),\n",
       " ('Federal Minimum Wage', '$7.25 an hour', 'Currently'),\n",
       " ('Federal Minimum Wage', 'Inflation', 'Not Pegged'),\n",
       " ('1968', '$2 an hour', 'Statutory Minimum Wage'),\n",
       " ('1968', 'About $10.90 an hour in 2017 dollars', 'Worth'),\n",
       " ('Hedge Funds', 'Oil Prices', 'Most_Bullish'),\n",
       " ('Hedge Funds', 'Further_Gains', 'Expect'),\n",
       " ('Hedge Funds', 'Risk', 'Ignore'),\n",
       " ('Hedge Funds', 'Record_Net_Long_Position', 'Hold'),\n",
       " ('Hedge Funds', '1183 Million Barrels', 'Amount'),\n",
       " ('Hedge Funds', 'Record_Net_Long_Positions', 'Have'),\n",
       " ('Hedge Funds', 'Net_Long_Positions', 'Have'),\n",
       " ('Hedge Funds', 'Large_Net_Long_Positions', 'Have'),\n",
       " ('Hedge Funds', 'Stretched_Position', 'Have'),\n",
       " ('Hedge Funds', 'Downside_Risk', 'Poses'),\n",
       " ('Hedge Funds', 'Liquidation_Risk', 'Ignore'),\n",
       " ('Hedge Funds', 'Prospect_Of_Further_Price_Increases', 'Focus'),\n",
       " ('Hedge Funds', 'Bullish', 'Remain'),\n",
       " ('Hedge Funds', 'Risk_Is_Some_Way_Off', 'Conclude'),\n",
       " ('Hedge Funds', 'Magnify', 'Long_Positions'),\n",
       " ('Portfolio Managers', 'Record_1328 Million Barrels', 'Hold'),\n",
       " ('Portfolio Managers', 'Long_Positions', 'Hold'),\n",
       " ('Portfolio Managers', 'Short_Positions', 'Hold'),\n",
       " ('Fund Managers', 'More_Than_Nine_Long_Positions', 'Hold'),\n",
       " ('Fund Managers', 'Short_Positions', 'Hold'),\n",
       " ('Downside_Risk', 'Resurgence_Of_US_Shale_Oil_Production', 'Come'),\n",
       " ('Global Economy', 'Synchronised_Upswing', 'Is'),\n",
       " ('World Trade', 'Fastest_Rate', 'Grow'),\n",
       " ('Stocks', 'Significantly', 'Fall'),\n",
       " ('Oil Demand', 'Rapidly', 'Grow'),\n",
       " ('OPEC', 'Production_Pact', 'Extend'),\n",
       " ('OPEC', 'Oil_Market', 'Tighten'),\n",
       " ('OPEC', 'Prices_To_Overshoot', 'Allow'),\n",
       " ('OPEC', 'Why', 'Explain'),\n",
       " ('OPEC', 'Halt_Production_Cuts', 'Force'),\n",
       " ('Benchmark_Brent_Prices', 'Towards_70_A_Barrel', 'Move'),\n",
       " ('Prices', 'More_Scope_To_Climb', 'Have'),\n",
       " ('WTI_Prices', 'Above_60_A_Barrel', 'Now'),\n",
       " ('Shale_Output', 'Climb_Faster_Than_Expected', 'Start'),\n",
       " ('Federal Reserve', 'short-term interest rates', 'Raise'),\n",
       " ('Federal Reserve', 'U.S. economic growth', 'Upgrade'),\n",
       " ('Five-year U.S. yield', 'April 2011', 'Highest level'),\n",
       " ('Investors', 'clues', 'Await'),\n",
       " ('U.S. Dec ISM manufacturing data', 'expectations', 'Beat'),\n",
       " ('U.S. 2-year yield', '9-year peak', 'Touches'),\n",
       " ('Companies', '$35 bln high-grade bonds', 'Sell'),\n",
       " ('Companies', '$35 billion', 'Sell'),\n",
       " ('IFR', 'market action after ISM data', 'Update'),\n",
       " ('Jason Celente', 'Insight Investment', 'Senior portfolio manager'),\n",
       " ('Wednesday', 'U.S. yields', 'Drop'),\n",
       " ('ISM factory index', '59.7', 'Unexpectedly rise'),\n",
       " ('Analysts', 'Reuters', 'Polled'),\n",
       " ('Evidence', 'factory sector', 'Expansion'),\n",
       " ('Fed', '3 times', 'Increase rates'),\n",
       " ('Minutes', '2 p.m.', 'Release'),\n",
       " ('FOMC', 'biggest rewrite', 'Passage'),\n",
       " ('FOMC', 'business activity', 'View'),\n",
       " ('Ten-year Treasury yield', '0.5 basis point', 'Down'),\n",
       " ('30-year yield', '0.6 basis point', 'Down'),\n",
       " ('Two-year yield', '9-year high', 'Reach'),\n",
       " ('Two-year yield', '1.931 percent', 'Last')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb0bf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3b1041af20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "graph.write_to_gml(\"test_graph.gml\")\n",
    "G = nx.read_gml(\"test_graph.gml\")\n",
    "nt = Network(notebook=True, cdn_resources='in_line')\n",
    "nt.from_nx(G)\n",
    "nt.show(\"network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b769a7da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import GraphQAChain\n",
    "chain = GraphQAChain.from_llm(ChatNVIDIA(model=\"mixtral_8x7b\", temperature=0), graph=graph, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3121dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphQAChain chain...\u001b[0m\n",
      "Entities Extracted:\n",
      "\u001b[32;1m\u001b[1;3mCalifornia, minimum wage\n",
      "\n",
      "---\n",
      "\n",
      "Explanation:\n",
      "\n",
      "The two entities present in the text are 'California' and 'minimum wage'. 'California' is a proper noun and a place, while 'minimum wage' is a common noun phrase that refers to the lowest hourly wage that an employer may legally pay to an employee.\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3mCalifornia Raise Minimum Wage\n",
      "California Impact More than 2 million workers\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In California, there has been a move to increase the minimum wage, which will impact more than 2 million workers. The exact details and timeline of the increase are not specified, but it is clear that a significant number of workers in the state will be affected by this change. Employers will need to adjust their payrolls accordingly, and workers can expect to see an increase in their earnings.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Explain what is going on with minimum wage in California.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9751d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"tell me what you know about Goldman Sachs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c37e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.run(\"How do hedge fund managers mitigate liquidataion risk?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"Which securities had the highest growth rate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db34c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
